# Contexto del Proyecto - Transformada de Hough en CUDA

AnÃ¡lisis completo del proyecto para referencia de implementaciÃ³n.

---

## ğŸ“‹ INFORMACIÃ“N GENERAL

**Proyecto:** #3 - Transformada de Hough usando CUDA  
**Curso:** ComputaciÃ³n Paralela y Distribuida  
**InstituciÃ³n:** Universidad del Valle de Guatemala  
**Fecha de Entrega:** Semana del 12-14 de noviembre  
**Grupo:** MÃ¡ximo 3 personas

---

## ğŸ¯ OBJETIVOS DEL PROYECTO

1. **Conocer** aplicaciÃ³n prÃ¡ctica de la memoria Constante de GPU
2. **Aprovechar** caracterÃ­sticas de memorias Global, Compartida y Constante
3. **Implementar** algoritmo clÃ¡sico de Computer Vision en arquitectura paralela

---

## ğŸ“– DESCRIPCIÃ“N DEL ALGORITMO

### Â¿QuÃ© es la Transformada de Hough?
- TÃ©cnica de Computer Vision para **detectar lÃ­neas rectas** en imÃ¡genes blanco y negro
- Sistema de **votaciÃ³n**: cada pixel "iluminado" vota por lÃ­neas posibles a las que pertenece
- Las lÃ­neas con **mÃ¡s votos** representan lÃ­neas reales en la imagen

### FÃ³rmula Principal
```
r(Î¸) = xÂ·cos(Î¸) + yÂ·sin(Î¸)
```
Donde:
- `r`: distancia del origen a la lÃ­nea
- `Î¸`: Ã¡ngulo perpendicular a la lÃ­nea
- `(x,y)`: coordenadas del pixel (origen en centro de imagen)

### ParÃ¡metros de DiscretizaciÃ³n
- **Î¸ (theta):** 90 bins, incrementos de 2Â°, rango [0Â°, 180Â°)
- **r (distancia):** 100 bins, rango [-rMax, rMax]
- **rMax:** `sqrt(wÂ² + hÂ²) / 2` (diagonal mÃ¡xima desde centro)
- **rScale:** `2 * rMax / rBins`

---

## ğŸ“‚ ESTRUCTURA DEL CÃ“DIGO BASE

### Archivos Principales
```
proyecto/
â”œâ”€â”€ houghBase.cu          # ImplementaciÃ³n principal CUDA
â”œâ”€â”€ common/
â”‚   â”œâ”€â”€ pgm.h            # Clase para leer imÃ¡genes PGM
â”‚   â””â”€â”€ pgm.cpp          # (compilado a pgm.o)
â”œâ”€â”€ Makefile             # ConfiguraciÃ³n de compilaciÃ³n
â”œâ”€â”€ .gitignore           # Archivos ignorados por git
â””â”€â”€ test.cu              # Test simple de CUDA
```

### Funciones Implementadas

#### âœ… YA IMPLEMENTADO en `houghBase.cu`:

1. **`CPU_HoughTran(...)`**
   - VersiÃ³n secuencial CPU de referencia
   - Calcula acumulador completo en host
   - Usado para validar resultados GPU

2. **`accumulateHoughGPU<<< >>> (...)`** âš ï¸ BASELINE
   - Kernel GPU con **solo memoria Global**
   - 1 thread por pixel
   - ConfiguraciÃ³n: `blockNum = (w*h + 256 - 1) / 256` bloques de 256 threads
   - Usa `atomicAdd` para evitar race conditions
   - **gloID calculado:** `blockIdx.x * blockDim.x + threadIdx.x`

3. **`computeSinCosTable(...)`**
   - Pre-calcula valores de sin/cos en host
   - Evita operaciones trigonomÃ©tricas costosas en GPU

4. **`saveAccumulatorAsPGM(...)`**
   - Guarda acumulador como imagen PGM normalizada
   - Formato: ancho=degreeBins, alto=rBins

5. **MediciÃ³n de Tiempo**
   - âœ… Implementado con CUDA events
   - Mide solo tiempo de kernel (no incluye transfers)

6. **LiberaciÃ³n de Memoria**
   - âœ… Ya libera: `d_in, d_hough, d_Cos, d_Sin`
   - âœ… Ya libera: `h_hough, cpuht, pcCos, pcSin`

---

## âœ… ESTADO ACTUAL - CÃ“DIGO FUNCIONAL COMPLETADO

### **âœ… IMPLEMENTACIONES COMPLETADAS:**

#### **Tarea 1: âœ… VersiÃ³n Global (Baseline)**
- [x] Kernel `accumulateHoughGPU` funcionando
- [x] Usa memoria global para tablas sin/cos
- [x] LiberaciÃ³n de memoria implementada

#### **Tarea 4: âœ… VisualizaciÃ³n de LÃ­neas**
- [x] FunciÃ³n `drawDetectedLines()` implementada
- [x] Genera imÃ¡genes PPM (`.ppm`) con lÃ­neas rojas superpuestas
- [x] Threshold automÃ¡tico: `max(promedio + 2*stddev, max/4)`
- [x] Detecta y dibuja lÃ­neas con votos > threshold

#### **Tarea 5: âœ… Memoria Constante**
- [x] Variables `__constant__ float d_Cos_const[degreeBins]` declaradas
- [x] Variables `__constant__ float d_Sin_const[degreeBins]` declaradas
- [x] Kernel `GPU_HoughTranConst()` implementado
- [x] Usa `cudaMemcpyToSymbol()` para copiar a memoria constante
- [x] Kernel no requiere parÃ¡metros de tablas sin/cos

#### **Tarea 8: âœ… Memoria Compartida**
- [x] Kernel `GPU_HoughTranShared()` implementado
- [x] Acumulador local `__shared__ int localAcc[degreeBins * rBins]`
- [x] InicializaciÃ³n distribuida entre threads del bloque
- [x] Dos barreras `__syncthreads()` correctamente ubicadas
- [x] Votos en acumulador local + copia final a global
- [x] Usa memoria constante para tablas sin/cos

#### **âœ… CÃ“DIGO MODULAR:**
- [x] FunciÃ³n `runKernelVersion()` para ejecutar cualquier versiÃ³n
- [x] Main permite ejecutar versiÃ³n especÃ­fica o todas: `./hough image.pgm [1|2|3|0]`
  - `1` = Solo Global Memory
  - `2` = Solo Constant Memory
  - `3` = Solo Shared Memory
  - `0` = Todas las versiones (default)
- [x] Salidas separadas por versiÃ³n: `output_v1.pgm`, `lines_v1.ppm`, etc.
- [x] VerificaciÃ³n automÃ¡tica contra CPU para cada versiÃ³n
- [x] MediciÃ³n de tiempo con CUDA events

#### **âœ… ARCHIVOS GENERADOS:**
- `output_v1.pgm` - Acumulador versiÃ³n Global
- `output_v2.pgm` - Acumulador versiÃ³n Constante
- `output_v3.pgm` - Acumulador versiÃ³n Compartida
- `lines_v1.ppm` - LÃ­neas detectadas versiÃ³n Global
- `lines_v2.ppm` - LÃ­neas detectadas versiÃ³n Constante
- `lines_v3.ppm` - LÃ­neas detectadas versiÃ³n Compartida

---

## ğŸ“‹ TAREAS PENDIENTES PARA CONTINUACIÃ“N

### **Benchmarking y AnÃ¡lisis (Tareas 2, 6, 9):**
- [ ] Ejecutar **mÃ­nimo 10 mediciones** por cada versiÃ³n
- [ ] Registrar tiempos en bitÃ¡cora para anÃ¡lisis estadÃ­stico
- [ ] Calcular promedio, desviaciÃ³n estÃ¡ndar, mÃ­nimo, mÃ¡ximo
- [ ] Comparar rendimiento entre las 3 versiones

### **DocumentaciÃ³n TÃ©cnica (Tareas 3, 7, 10):**
- [ ] **ExplicaciÃ³n TeÃ³rica:**
  - CÃ¡lculo de `xCoord` y `yCoord`
  - JustificaciÃ³n del centrado de origen
  - ExplicaciÃ³n de inversiÃ³n del eje Y
- [ ] **AnÃ¡lisis Memoria Constante:**
  - PÃ¡rrafo explicando implementaciÃ³n
  - Efecto en rendimiento vs memoria global
  - Diagrama de flujo de datos
- [ ] **AnÃ¡lisis Memoria Compartida:**
  - PÃ¡rrafo explicando implementaciÃ³n
  - Efecto en rendimiento vs otras versiones
  - Diagrama de flujo de datos

### **Informe Final:**
- [ ] Documento PDF con formato UVG
- [ ] BitÃ¡coras de tiempo consolidadas
- [ ] AnÃ¡lisis comparativo de las 3 implementaciones
- [ ] Conclusiones sobre uso de diferentes tipos de memoria

---

## ğŸ“Š ENTREGABLES FINALES

### CÃ³digo (45 puntos)
- [x] VersiÃ³n CUDA funcional con 3 tipos de memoria
- [x] GeneraciÃ³n de imagen con lÃ­neas detectadas
- [x] DocumentaciÃ³n y comentarios
- [x] Uso correcto de barreras (`__syncthreads()`)
- [x] LiberaciÃ³n completa de memoria

### Informe PDF (20 puntos)
- [ ] MÃ­nimo 1 pÃ¡gina sobre algoritmo + implementaciÃ³n CUDA
- [ ] Formato UVG: carÃ¡tula, Ã­ndice, introducciÃ³n, cuerpo, conclusiones
- [ ] BitÃ¡coras de tiempo (mÃ­nimo 10 mediciones Ã— 3 versiones)
- [ ] AnÃ¡lisis memoria Constante + diagrama
- [ ] AnÃ¡lisis memoria Compartida + diagrama
- [ ] MÃ­nimo 3 citas bibliogrÃ¡ficas

### PresentaciÃ³n (20 puntos)
- [ ] PresentaciÃ³n ejecutiva del proyecto
- [ ] Vestimenta business casual
- [ ] CalificaciÃ³n individual segÃºn participaciÃ³n

### Repositorio
- [ ] CÃ³digo subido (no solo link)
- [ ] Link al repositorio

---

## ğŸ”§ CONSIDERACIONES TÃ‰CNICAS

### Memorias CUDA

| Tipo | UbicaciÃ³n | Scope | Velocidad | Uso en Proyecto |
|------|-----------|-------|-----------|-----------------|
| **Global** | Device DRAM | Todos los threads | Lenta (~400 ciclos) | Imagen input, acumulador final |
| **Constante** | Device + Cache | Read-only, todos | RÃ¡pida si broadcast | Tablas sin/cos (90 valores) |
| **Compartida** | On-chip SM | Por bloque | Muy rÃ¡pida (~4 ciclos) | Acumulador local por bloque |

### LÃ­mites Importantes
- Memoria Constante: 64 KB total, 8 KB cache por SM
- Memoria Compartida: depende del GPU (~48 KB por SM tÃ­pico)
- `localAcc` requiere: `90 bins Ã— 100 bins Ã— 4 bytes = 36 KB` âœ… cabe

### Operaciones CrÃ­ticas
- `atomicAdd`: necesario para evitar race conditions
- `__syncthreads()`: sincronizar threads de un bloque
- `__fmaf_rn()`: multiply-add optimizado
- `__float2int_rn()`: conversiÃ³n con redondeo

---

## ğŸ¨ DETALLES DE IMPLEMENTACIÃ“N

### Sistema de Coordenadas
```
Imagen original (0,0) = esquina superior izquierda

Transformado a:
      x
      â†‘
      |
â†-----+----â†’ y
      |
      â†“
      
Centro = (w/2, h/2)
xCoord = i - xCent
yCoord = yCent - j  (invertido!)
```

### Flujo del Algoritmo
1. Leer imagen PGM (blanco y negro)
2. Pre-calcular sin/cos en host
3. Copiar imagen y tablas a GPU
4. **Cada thread procesa 1 pixel:**
   - Si pixel > 0: votar por 90 lÃ­neas posibles
   - Cada voto incrementa `acc[rIdx][tIdx]`
5. Copiar acumulador a host
6. Encontrar bins con mÃ¡s votos = lÃ­neas detectadas
7. Dibujar lÃ­neas sobre imagen original

---

## ğŸ“š RECURSOS Y REFERENCIAS

### DocumentaciÃ³n Oficial
- [CUDA Programming Guide](https://docs.nvidia.com/cuda/cuda-c-programming-guide/)
- [CUDA Performance Metrics](https://developer.nvidia.com/blog/how-implement-performance-metrics-cuda-cc/)

### Conceptos Clave a Investigar
- Hough Transform
- Constant Memory caching y broadcasting
- Shared Memory bank conflicts
- Atomic operations en CUDA
- Thread synchronization

---

## âš ï¸ NOTAS IMPORTANTES

1. **No usar `cudaMalloc` para memoria Constante**, solo declarar con `__constant__`
2. **Usar `cudaMemcpyToSymbol`** en lugar de `cudaMemcpy` para constante
3. **Siempre sincronizar** antes y despuÃ©s de usar shared memory
4. **Threshold para lÃ­neas:** experimentar con valores (ej: max/2, promedio+2Ïƒ)
5. **Formato imagen salida:** cualquier formato comÃºn (PNG, JPG)
6. **LibrerÃ­a para dibujar:** puede usar OpenCV, STB, o similar

---

---

## ğŸš€ INSTRUCCIONES PARA CONTINUACIÃ“N

### **CompilaciÃ³n:**
```bash
make
```

### **EjecuciÃ³n:**
```bash
# Ejecutar todas las versiones (recomendado para benchmarking)
./hough imagen.pgm

# Ejecutar versiÃ³n especÃ­fica
./hough imagen.pgm 1  # Solo Global Memory
./hough imagen.pgm 2  # Solo Constant Memory
./hough imagen.pgm 3  # Solo Shared Memory
```

### **Archivos de Salida:**
- `output_v1.pgm`, `output_v2.pgm`, `output_v3.pgm` - Acumuladores
- `lines_v1.ppm`, `lines_v2.ppm`, `lines_v3.ppm` - LÃ­neas detectadas

---

**Estado Actual del CÃ³digo:**
âœ… **TODAS las implementaciones de cÃ³digo COMPLETADAS**
âœ… 3 versiones funcionales: Global, Constante, Compartida
âœ… VisualizaciÃ³n de lÃ­neas implementada
âœ… CÃ³digo modular para benchmarking
â³ **Pendiente:** Solo benchmarking y documentaciÃ³n